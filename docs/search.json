[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stanley Lo",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Plots-Project1.html",
    "href": "Plots-Project1.html",
    "title": "Global Seafood Production & NFL Weekly Attendance Analysis",
    "section": "",
    "text": "This analysis explores the global seafood production dataset provided by TidyTuesday and we can see the trends in seafood production through time.\nFrom the plot, we see that global seafood production has increased steadily into the 2000s and since then, has leveled off and is staying consistently high.\nCitation: https://ourworldindata.org/fish-and-overfishing\nThis analysis looks at the NFL attendance trends provided by TidyTuesday.\nFrom the plot, we can see that weekly attendance since 2000 for NFL games has stayed relatively constant with the median weekly attendance staying high through 2019.\nCitation: https://www.pro-football-reference.com/years/2018/attendance.htm\n\n\nlibrary(tidyverse)\nseafood &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-10-12/seafood-and-fish-production-thousand-tonnes.csv')\n\nggplot(seafood, aes(x = Year, y = `Commodity Balances - Livestock and Fish Primary Equivalent - Pelagic Fish - 2763 - Production - 5510 - tonnes`)) +\n  geom_line() +\n  labs(title = \"Global Seafood Production Over   Time\", x = \"Year\", y = \"Production (tonnes)\")\n\n\n\n\n\n\n\n\n\nlibrary(tidyverse)\nnfl_attendance &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2020/2020-02-04/attendance.csv')\n\nggplot(nfl_attendance, aes(x = year, y = weekly_attendance)) +\n  geom_boxplot(aes(group = year), fill = \"blue\", alpha = 0.7) + labs(title = \"NFL Weekly Attendance by Year\", x = \"Year\", \n  y = \"Weekly Attendance\")"
  },
  {
    "objectID": "Friends-Character-Data.html",
    "href": "Friends-Character-Data.html",
    "title": "Who Asks the Most Questions in Friends?",
    "section": "",
    "text": "Questions of Interest: “How do questions change throughout the seasons of Friends, and which characters ask the most questions?”\n\nlibrary(friends)\nlibrary(tidyverse)\nlibrary(stringr)\nlibrary(ggplot2)\ndata(friends)\n\nfriends &lt;- friends |&gt;\nmutate(word_count = str_count(text, \"\\\\w+\"), \nfirst_word = str_extract(text, \"^\\\\w+\"),\nends_with_question_mark = str_detect(text, \"\\\\?$\"))\n\n\nquestion_words &lt;- \"Who|What|When|Where|Why|How\"\nfriends &lt;- friends |&gt;\nmutate(starts_with_question_word = str_detect(text,  str_c(\"^(\", question_words, \")\\\\b\")),\ncontains_question_word = str_detect(text, str_c(\"\\\\b(\", question_words, \")\\\\b\")),\nquestion_word_count = str_count(text, str_c(\"\\\\b(\", question_words, \")\\\\b\")))\n\nfriends &lt;- friends |&gt;\nmutate(complex_question = str_detect(text, str_c(\"^(?!(\", question_words, \")\\\\b).*\\\\?$\")))\n\n\nseason_questions &lt;- friends |&gt;\ngroup_by(season) |&gt;\nsummarise(question_ratio = mean(ends_with_question_mark),\ncomplex_question_ratio = mean(complex_question))\n\n\nggplot(season_questions, aes(x = season)) +\ngeom_line(aes(y = question_ratio, color = \"All Questions\")) +\ngeom_line(aes(y = complex_question_ratio, color = \"Complex Questions\")) + labs(title = \"Question Usage Throughout Friends Seasons\", x = \"Season\", y = \"Proportion of Lines\", color = \"Question Type\")\n\n\n\n\n\n\n\n\nThis graph shows how question usage is changing throughout the multiple seasons of the show Friends. We see that all questions asked are stable but a slight dip in the proportion of lines dedicated to questions in the middle of the graph. At the same time, complex questions took a hit as well but since the proportional difference is only around 0.04, it is not a significant drop in questions being asked in the show Friends.\n\nmain_characters &lt;- c(\"Monica Geller\", \"Rachel Green\", \"Phoebe Buffay\", \"Chandler Bing\", \"Joey Tribbiani\", \"Ross Geller\")\n\ncharacter_questions &lt;- friends |&gt;\nfilter(speaker %in% main_characters) |&gt;\ngroup_by(speaker) |&gt;\nsummarise(question_ratio = mean(ends_with_question_mark),\nquestion_word_ratio = mean(contains_question_word),\ntotal_lines = n()) |&gt;\narrange(desc(question_ratio))\n\n\nggplot(character_questions, aes(x = speaker, y = question_ratio)) + geom_bar(stat = \"identity\", fill = \"blue\") + labs(title = \"Proportion of Questions Asked by Main Characters\", x = \"Character\", y = \"Proportion of Lines Ending with Question Mark\")\n\n\n\n\n\n\n\n\nFrom our analysis of characters and the questions they ask. We see that Monica seems to be the character that asks the most questions with around 24% of her lines being QUESTIONS which is insane. Besides that, the rest of the characters also have similar rates of asking questions with everyone except Phoebe having a proportion of lines ending with question marks above 20%. Because Monica is asking the most questions, we see that Monica is possibly also questioning the decisions of her Friends much more than the others. This could show the differentiated strategy in which the directors are trying to develop the personalities of each character.\nCITATIONS:\nhttps://github.com/EmilHvitfeldt/friends\nCharacter Mining Project: https://www.emorynlp.org/#"
  },
  {
    "objectID": "Simulation.html",
    "href": "Simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "Research Question: “Do Action Movies in the summer get different IMDB ratings than Drama Movies in the summer?”\nThe variables for this question would include the Genres and the average IMBD rating.\nThe null hypothesis: Action Movies do not have significantly different IMBD ratings compared to Drama Movies.\nAlternative Hypothesis: Action Movies do have significantly different IMBD ratings compared to Drama Movies.\nThis analysis checks whether observed rating differences between Action and Drama films reflect genre qualities or random variation. Using permutation testing, we’ll simulate 10,000 random genre assignments to build a null distribution of rating differences.\n\nlibrary(tidyverse)\nlibrary(infer)  \n\nsummer_movies &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-07-30/summer_movies.csv\")\ngenres &lt;- read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-07-30/summer_movie_genres.csv\")\n\naction_drama &lt;- genres |&gt;\n  filter(genres %in% c(\"Action\", \"Drama\")) |&gt;\n  inner_join(select(summer_movies, -genres), by = \"tconst\") |&gt;  \n  group_by(tconst) |&gt;\n  filter(n() == 1) |&gt;\n  ungroup() |&gt;\n  mutate(\n    genres = factor(genres),\n    average_rating = as.numeric(average_rating)\n  ) |&gt;\n  drop_na(average_rating, genres)\n\ngenre_permutation_test &lt;- function(data, n_perm = 1000) {\n  effect &lt;- data |&gt;\n    specify(average_rating ~ genres) |&gt;  \n    calculate(stat = \"diff in means\", order = c(\"Action\", \"Drama\"))\n  \n  null_dist &lt;- data |&gt;\n    specify(average_rating ~ genres) |&gt;  \n    hypothesize(null = \"independence\") |&gt;\n    generate(reps = n_perm, type = \"permute\") |&gt;\n    calculate(stat = \"diff in means\", order = c(\"Action\", \"Drama\"))\n  \n  p_value &lt;- get_p_value(null_dist, obs_stat = effect, direction = \"both\")\n  \n  list(\n    observed_effect = effect,\n    null_distribution = null_dist,\n    p_value = p_value\n  )\n}\n\nset.seed(2025)\ngenre_results &lt;- genre_permutation_test(action_drama, 10000)\n\n\naction_drama |&gt;\n  ggplot(aes(x = average_rating, fill = genres)) +\n  geom_density(alpha = 0.6) +\n  labs(title = \"Rating Distribution by Genre\",\n       x = \"Average Rating\",\n       y = \"Density\", fill = \"Genre\") +\n  scale_fill_manual(values = c(\"red\", \"blue\"))\n\n\n\n\n\n\n\n\nSince the action movies are showing a left skew and has a mean of 6.2 compared to the mean of the drama movies are 6.5 which shows a slight difference in the ratings.\n\ngenre_results$null_distribution |&gt;\n  visualize() +\n  shade_p_value(genre_results$observed_effect, direction = \"both\") + labs(\n    title = \"Null Distribution of Rating Differences\",\n    subtitle = \"Based on Permutation Testing (10,000 Simulations)\",\n    x = \"Difference in Means (Action - Drama)\",\n    y = \"Frequency\"\n  )\n\n\n\n\n\n\n\nobserved_diff &lt;- genre_results$observed_effect$stat\np_val &lt;- genre_results$p_value\n\nThis shows the difference is extremely small and the distribution is centered at zero and the difference is at the tail of the null distribution, therefore, this cannot have happened by chance alone.\n\nn_permutations &lt;- c(1000, 5000, 10000) |&gt;\n  set_names() |&gt;\n  map_dbl(\n    ~genre_permutation_test(action_drama, .x)$p_value |&gt; \n      as.numeric() \n  )\n\nFor this project, I investigated whether Action movies released in the summer have different IMDb ratings compared to Drama movies. I used a dataset from IMDb through TidyTuesday that includes genres and average ratings for summer movies. To test my hypothesis, I performed a permutation test by randomly shuffling genres 10,000 times to simulate the null hypothesis of no difference in ratings. I visualized the original data using a density plot to compare the distributions of ratings for Action and Drama movies, which showed that Drama movies tend to have slightly higher ratings on average. Finally, I plotted the null distribution of differences in means and observed that the actual difference lies in the tail. This suggests that genre does play a role in summer movie ratings."
  },
  {
    "objectID": "EthicsDataPower.html",
    "href": "EthicsDataPower.html",
    "title": "EthicsDataPower",
    "section": "",
    "text": "Work is Grounded in: [Examine] how power operates in the world today. This consists of asking who questions about data science: Who does the work (and who is pushed out)? Who benefits (and who is neglected or harmed)? Whose priorities get turned into products (and whose are overlooked)?1 How did we get to the point where data science is used almost exclusively in the service of profit (for a few), surveillance (of the minoritized), and efficiency (amidst scarcity)?\nSummary of Experiment: The Facebook Emotional Contagion Experiment, conducted by Kramer, Guillory, and Hancock in 2012, tested whether emotions are contagious online by manipulating the News Feeds of approximately 700,000 users without their knowledge. For one week, researchers reduced either positive or negative posts in users’ feeds to observe how this affects their emotional expression. The study found that users exposed to fewer positive posts were more likely to post negative updates, providing evidence of emotional contagion.The experiment faced significant controversy due to ethical concerns over informed consent and privacy violation.\n\nWhat is the permission structure for using the data? Was it followed?\n\nFacebook relied on its Terms of Service to justify using user data for the experiment. The ToS allowed Facebook to use data for research purposes, so technically, the company didn’t break any rules. However, this permission structure wasn’t enough to meet ethical standards. Users had no idea their data would be used for an experiment that manipulated their emotions. While Facebook followed its own policies, it ignored basic ethical principles like transparency and informed consent.\n\nWhat was the consent structure for recruiting participants? Were participants aware of how their data would be used?\n\nThere was no real consent structure in place for this experiment. Users weren’t told they were part of a psychological study, and they weren’t asked if they agreed to have their News Feeds manipulated. Ethical research requires that participants know what they’re agreeing to but Facebook didn’t provide this information. Instead, they assumed users had agreed to everything through the ToS, which most people don’t even read. This lack of informed consent is one of the main reasons why the study faced so much backlash.\n\nIs the data identifiable? All of it? Some of it? In what way? Are the data sufficiently anonymized or old to be free of ethical concerns? Is anonymity guaranteed?\n\nThe study didn’t fully anonymize user data during the experiment because it directly manipulated peoples emotional states based on their News Feeds. Even though the final results didn’t include names or personal details, anonymity wasn’t guaranteed. This is a problem because users weren’t aware their emotions were being tracked and influenced in real time.The lack of proper anonymization during the experiment raises serious ethical concerns about privacy and how companies handle user data.\n\nIs the data being used in unintended ways compared to its original purpose?\n\nYes, this experiment used data in ways that most users wouldn’t have expected when they signed up for Facebook. People probably assumed their data would be used for things like improving platform features or targeted advertising and not psychological experiments designed to manipulate their emotions. This kind of unexpected use of data shows how vague terms like “research purposes” in a ToS can lead to unethical practices. If Facebook wanted to use its platform for experiments like this, it should have been upfront with users.\nCitations:\nEthical Dilemma: Facebook emotional contagion experiment (patient consent, among other things). Kramer, A. D., Guillory, J. E., and Hancock, J. T. (2014), Experimental Evidence of Massive-Scale Emotional Contagion through Social Networks, Proceedings of the National Academy of Sciences of the United States of America, 111, 8788–8790.\nSecondary Article used: “Everything We Know About Facebook’s Secret Mood-Manipulation Experiment” by The Atlantic on June 28, 2014 https://www.theatlantic.com/technology/archive/2014/06/everything-we-know-about-facebooks-secret-mood-manipulation-experiment/373648/"
  },
  {
    "objectID": "Stanford Open Policing Analysis.html",
    "href": "Stanford Open Policing Analysis.html",
    "title": "Stanford Open Policing Analysis",
    "section": "",
    "text": "We are analyzing whether there is a difference in arrest rates and search rates among all the races being pulled over. In California, we have taken two cities from the Bay Area, San Francisco and Oakland, and one city from Southern California, Anaheim. We will analyze their data.\n\nlibrary(DBI)\n\nWarning: package 'DBI' was built under R version 4.4.3\n\nlibrary(RMariaDB)\n\nWarning: package 'RMariaDB' was built under R version 4.4.3\n\ncon_traffic &lt;- dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n\nSELECT \n    city,\n    subject_race,\n    COUNT(*) AS total_stops,\n    AVG(CASE WHEN arrest_made THEN 1 ELSE 0 END) AS arrest_rate\nFROM (\n    SELECT \n        'San Francisco' AS city,\n        YEAR(date) AS stop_year,\n        subject_race,\n        arrest_made\n    FROM ca_san_francisco_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n    \n    UNION ALL\n    \n    SELECT \n        'Oakland' AS city,\n        YEAR(date) AS stop_year,\n        subject_race,\n        arrest_made\n    FROM ca_oakland_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n    \n    UNION ALL\n    \n    SELECT \n        'San Jose' AS city,\n        YEAR(date) AS stop_year,\n        subject_race,\n        arrest_made \n    FROM ca_san_jose_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, subject_race\nORDER BY arrest_rate DESC;\n\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n  ggplot(arrest_data, aes(x = subject_race, y = arrest_rate, fill = city)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Arrest Rates by Race (2014-2017)\", x = \"Subject Race\", y = \"Arrest Rate\", fill = \"City\")\n\n\n\n\n\n\n\n\nBy This chart, we see that black people face higher arrest rates across every city and especially in Oakland where it is almost twice the arrest rate of the next race. Hispanics also face the second highest rates of arrest across the board.\n\nSELECT \n    city,\n    subject_race,\n    COUNT(*) AS total_stops,\n    ROUND(100.0 * AVG(CASE WHEN search_conducted THEN 1 ELSE 0 END), 2) AS search_rate\nFROM (\n    SELECT \n        'San Francisco' AS city,\n        subject_race,\n        search_conducted\n    FROM ca_san_francisco_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n    UNION ALL\n\n    SELECT \n        'Oakland' AS city,\n        subject_race,\n        search_conducted\n    FROM ca_oakland_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n    UNION ALL\n\n    SELECT \n        'San Jose' AS city,\n        subject_race,\n        search_conducted\n    FROM ca_san_jose_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, subject_race\nORDER BY city, search_rate DESC;\n\n\nlibrary(ggplot2)\nggplot(search_data, aes(x = subject_race, y = search_rate, fill = city)) + geom_col(position = \"dodge\") + labs(title = \"Search Rates by Race (2014-2017)\", x = \"Subject Race\", y = \"Search Rate (%)\", fill = \"City\")\n\n\n\n\n\n\n\n\nSimilar to the data for Arrest Rates, Search rates are higher across the board for black and hispanic people. However, in this case, Hispanic people sometimes have a higher search rate than black people such as in San Jose and the gap between black & hispanic people have closed to around similar rates in San Jose but not in Oakland and San Francisco.\nAll in all, this shows that in Major Cities in the Bay Area, Black and Hispanic people have higher search and arrest rates than other races. This may show that the police reforms that happened back in 2016 may not have fully solved the problem of high search and arrest rates for Black and Hispanic people.\nData is from: Stanford Open Policing Project: https://openpolicing.stanford.edu/data/\nCitation: Pierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  },
  {
    "objectID": "Stanford-Open-Policing-Analysis.html",
    "href": "Stanford-Open-Policing-Analysis.html",
    "title": "Stanford Open Policing Analysis",
    "section": "",
    "text": "We are analyzing whether there is a difference in arrest rates and search rates among all the races being pulled over. In California, we have taken two cities from the Bay Area, San Francisco and Oakland, and one city from Southern California, Anaheim. We will analyze their data.\n\nlibrary(DBI)\nlibrary(RMariaDB)\n\ncon_traffic &lt;- dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n\nSELECT \n    city,\n    subject_race,\n    COUNT(*) AS total_stops,\n    AVG(CASE WHEN arrest_made THEN 1 ELSE 0 END) AS arrest_rate\nFROM (\n    SELECT \n        'San Francisco' AS city,\n        YEAR(date) AS stop_year,\n        subject_race,\n        arrest_made\n    FROM ca_san_francisco_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n    \n    UNION ALL\n    \n    SELECT \n        'Oakland' AS city,\n        YEAR(date) AS stop_year,\n        subject_race,\n        arrest_made\n    FROM ca_oakland_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n    \n    UNION ALL\n    \n    SELECT \n        'San Jose' AS city,\n        YEAR(date) AS stop_year,\n        subject_race,\n        arrest_made \n    FROM ca_san_jose_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, subject_race\nORDER BY arrest_rate DESC;\n\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n  ggplot(arrest_data, aes(x = subject_race, y = arrest_rate, fill = city)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Arrest Rates by Race (2014-2017)\", x = \"Subject Race\", y = \"Arrest Rate\", fill = \"City\")\n\n\n\n\n\n\n\n\nBy This chart, we see that black people face higher arrest rates across every city and especially in Oakland where it is almost twice the arrest rate of the next race. Hispanics also face the second highest rates of arrest across the board.\n\nSELECT \n    city,\n    subject_race,\n    COUNT(*) AS total_stops,\n    ROUND(100.0 * AVG(CASE WHEN search_conducted THEN 1 ELSE 0 END), 2) AS search_rate\nFROM (\n    SELECT \n        'San Francisco' AS city,\n        subject_race,\n        search_conducted\n    FROM ca_san_francisco_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n    UNION ALL\n\n    SELECT \n        'Oakland' AS city,\n        subject_race,\n        search_conducted\n    FROM ca_oakland_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n\n    UNION ALL\n\n    SELECT \n        'San Jose' AS city,\n        subject_race,\n        search_conducted\n    FROM ca_san_jose_2020_04_01\n    WHERE YEAR(date) BETWEEN 2014 AND 2017\n) AS combined\nGROUP BY city, subject_race\nORDER BY city, search_rate DESC;\n\n\nlibrary(ggplot2)\nggplot(search_data, aes(x = subject_race, y = search_rate, fill = city)) + geom_col(position = \"dodge\") + labs(title = \"Search Rates by Race (2014-2017)\", x = \"Subject Race\", y = \"Search Rate (%)\", fill = \"City\")\n\n\n\n\n\n\n\n\nSimilar to the data for Arrest Rates, Search rates are higher across the board for black and hispanic people. However, in this case, Hispanic people sometimes have a higher search rate than black people such as in San Jose and the gap between black & hispanic people have closed to around similar rates in San Jose but not in Oakland and San Francisco.\nAll in all, this shows that in Major Cities in the Bay Area, Black and Hispanic people have higher search and arrest rates than other races. This may show that the police reforms that happened back in 2016 may not have fully solved the problem of high search and arrest rates for Black and Hispanic people.\nData is from: Stanford Open Policing Project: https://openpolicing.stanford.edu/data/\nCitation: Pierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10."
  }
]